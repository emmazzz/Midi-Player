# sched.srp -- a scheduler framework
#
# sched_init() prepares to run
#    creates globals rtsched and vtsched
# sched_run() runs the scheduler until sched_running is set to false
#    Note: this calls sched_poll, which client must define
#          (sched_poll() is a good place to process MIDI input, etc.)
#    Note 2: Only call sched_run() from serpent. See sched_launch()
# sched_launch() runs the scheduler by setting up a timer in wxserpent.
#    Note: this calls sched_poll, which client must define
#          (sched_poll() is a good place to process MIDI input, etc.)
#    Note 2: Only call sched_launch() from wxserpent. See sched_run().
#    Note 3: an optional parameter gives the polling period in ms.
#    
# Logical Time Theory
#    Scheduling associates an ideal time with every event (function call,
#      method invocation). The event is run as close to the logical
#      time as possible. Think of logical time is an idealized time or
#      specification. This section is mainly about where this
#      specification comes from. But before getting to that, we'll
#      describe the action of the scheduler: Logical times are mapped
#      to real time, and as soon as the actual real time reaches the
#      mapped logical time, the event is run. To map from logical time
#      to real time, Vscheduler's use a Time_map object to map to their
#      parent's time (Vscheduler's can form a tree with a Scheduler at
#      the root.) Scheduler's add time_offset to get from logical time
#      to real time.
#    Computing Logical Times. Logical times are normally relative to
#      another logical time. When you call cause(delta, ...), a new
#      event is created with the logical time of time + delta, where
#      time is the (ideal) logical time of the current event. If you
#      cause an event, and that event causes another event, and so on,
#      the logical times are the precise accumulation of all the
#      delta's and therefore there is no drift or quantization due to
#      execution time or finite polling rates. But what about the
#      first event in such a sequence? When some external (to the
#      scheduler) execution, e.g. from a user interface or the
#      network, needs to schedule an event, you must call start_use(),
#      which updates a scheduler as if the scheduler were running
#      an event whose logical time maps exactly to the current real
#      time. Then, cause(delta) will schedule an event at offset
#      delta from the current real time. Note that while this is
#      happening, time passes, so even if you schedule an event
#      with cause(0, ...), it might run *after* some other
#      previously scheduled event whose logical time is already
#      in the past.
#    Nested start_use() Calls. If you were already running a
#      scheduled event and called start_use(), and if start_use()
#      updated the scheduler according to real time, then you would
#      lose the nice property that cause(delta, ...) is relative
#      to ideal time. Instead, the delta would be added to real time.
#      To avoid this, you could promise never to call start_use()
#      when running an event, but that could be hard to avoid.
#      Instead, if you call start_use() while running a scheduled
#      event, the ideal time of the scheduler is not adjusted.
#      To make this work, you *must* balance every call to
#      start_use() with a matching call to finish_use(). E.g.
#          my_sched.start_use()
#          my_sched.cause(delta, ...)
#          my_sched.finish_use()
#   Switching Schedulers. When a scheduler dispatches an event,
#     it sets its time field to the current logical time, and
#     a Vscheduler's ancestors, all the way up to the root
#     Scheduler, also set their time fields. The global the_sched
#     is also set to the scheduler dispatching the current event.
#     If you want to schedule an event on another scheduler, you
#     should call start_use() on that scheduler to adjust its
#     time field to the current logical time. Then cause() will
#     work as you would expect: The event will be scheduled
#     relative to the current (ideal) logical time. Of course,
#     a matching finish_use() should be called. Note that
#     finish_use() will not restore the_sched to its previous
#     value.
# 
# Globals:
#    rtsched - the single real-time scheduler object
#    vtsched - an initial virtual-time scheduler object (more can be created)
#    the_sched - tells what scheduler dispatched the currently running event
#                (can be changed by a call to some_scheduler.use())
#    sched_running - set this to false to exit sched_run loop
#    sched_nesting - nesting level of start_use()/finish_use() brackets
#    sched_ideal_time - the idealized real time of the current event
#    EPSILON - a small value, larger than rounding error
#    INFINITY - a time that will never be reached
#
# APIs: External interfaces for the classes, i.e. the methods that clients 
#       should call and what they do (see actual methods for details)
#
# class Scheduler:
#    time - instance variable with current time in Scheduler time coordinates
#    cause() - schedule an event
#    poll(when) - call this frequently to dispatch pending events
#    get_tick() - return ideal (not current) value of get_time() in ticks
#    start_use() - start pretending we are in a caused event dispatched by
#      this scheduler, logical time will not advance until finish_use() is
#      called
#    finish_use() - finish pretending we are in a caused event
#      (start_use() and finish_use() are mainly used when an "external"
#      event from a user interface, MIDI, or network needs to schedule
#      something.)
#    r2v(r) - returns r
#    v2r(v) - returns v
#    bump_time() - advance scheduler's time, used for synchronization
#
#
# class Vscheduler:
#    Vscheduler(sched) - creates a virtual scheduler that maps time from sched
#    time - instance variable with current time in VScheduler time coordinates
#    cause() - schedule an event
#    flush() - unschedule all pending events
#    start_use() - start pretending we are in a caused event, logical time
#      will not advance until finish_use() is called.
#    finish_use() - finish pretending we are in a caused event
#      (start_use() and finish_use() are mainly used when an "external"
#      event from a user interface, MIDI, or network needs to schedule
#      something.)
#    r2v(r) - map from real time to virtual time
#    v2r(v) - map from virtual time to real time
#    set_vtime(v) - set the current virtual time to v
#    set_bpm(bpm) - set bpm units of virtual time = 60s of real time
#                   Note: if virtual units are beats, bpm is beats per minute.
#    set_bps(bps) - set bps units of virtual time = 1s of real time
#                   Note: if virtual units are beats, bps is beats per second.
#    set_period(p) - set 1 unit of virtual time = p seconds of real time

require "debug"
require "utils"

sched_trace = nil

EPSILON = 0.000001

INFINITY = 1000000.0 // many hours

STOPPED_BPS = EPSILON // one beat every million minutes (1.9 years)

require "timemap"

# to cause an event at an absolute time (either beats, virtual time, or
# real time, call cause like this:
#       the_sched.cause(absolute(abs_time), obj, meth, ...)
# The_sched must be well-defined. If you are invoking cause on a specific
# scheduler, call the start_use() method first:
#       my_scheduler.start_use()
#       my_scheduler.cause(absolute(abs_time), obj, meth, ...)
#       my_scheduler.finish_use()


def absolute(x)
    # compute delta for cause corresponding to absolute logical time x
    x - the_sched.time

def real_delay(delta)
    # compute delta for cause relative to real time,  not logical time
    # Example: If you are behind schedule and want to schedule an
    #   event 0.1s from the current real time (so delays will accumulate)
    #   call the_sched.cause(real_delay(0.1), ...)
    # delta is in local (logical) units. If you want delta in seconds,
    #   call rtsched.start_use() and then call the_sched.cause()
    absolute(the_sched.r2v(time_get()) + delta)


sched_nesting = 0 // non-zero when running scheduled events
nesting_error_printed = t

class Scheduler
    var time  // this is the ideal current time
    var queue
    var next_time // either INFINITY or queue.last()[0]
    var time_offset // the scheduler starting time

    def init()
        time = 0.0 // ideal real time
        next_time  = INFINITY
        queue = []

    # schedule an event: 
    #    when is the time offset from RNOW until the event time
    #    target is an object that will receive message
    #        (target should be nil for an ordinary function call)
    #    message is a symbol (single quotes) naming method or function
    #    remaining parameters are passed to method or function
    def cause(when, target, message, rest parms)
        // display "cause", time_get(), when, time, target, message, parms, queue
        when = time + when // when is an offset from current time
        queue.append([when, target, message, parms])
        queue.resort()
        // no need for separate reschedule() as in Vscheduler
        if len(queue) > 0
            next_time = queue.last()[0]
        else
            next_time = INFINITY


    # must be called periodically for Scheduler to work correctly
    #     when is the current real time returned by time_get()
    def poll(when)
        // NOTE: it is ok to have more than one Scheduler instance
        // (although odd), but you cannot have one scheduler polling
        // another. 
        if sched_nesting > 0
            // this can happen if we get into a dialog box
            if not nesting_error_printed:
                // just print once per sequence of nesting errors
                nesting_error_printed = true
                print "Recursive call to Scheduler::poll() or ";
                print "Scheduler::start_use()\n    not closed by ";
                print "Scheduler::finish_use(). Returning from poll()."
            return
        nesting_error_printed = false
        sched_ideal_time = when
        when = when - time_offset
        sched_nesting = 1
        while when >= next_time - EPSILON
            var event = queue.unappend()
            if len(queue) > 0
                next_time = queue.last()[0]
            else
                next_time = INFINITY
            time = event[0]
            the_sched = this
            var target = event[1]
            var message = event[2]
            var parms = event[3]
            // display "dispatch", time_get(), time, target, message, parms
            general_apply(target, message, parms)
        sched_nesting = 0

        // after all scheduled events have been run,
        // update time to reflect the current real time:
        time = when


    # return an idealized integer count of milliseconds corresponding
    # to the timestamp used by PortMidi. Note that the timestamp used
    # by PortMidi is equal to int(time_get() * 1000)
    def get_tick()
        // note: if you are not running the scheduler, time_offset is nil
        // and this will raise an (intentional) error. It means you are
        // trying to schedule MIDI data before starting the scheduler.
        // Also, if you are not running a scheduled event, you must call
        // start_use() before get_tick(). Otherwise, the time field
        // will be the ideal time of the last event that ran, so it
        // may be a time in the distant past.
        if sched_nesting == 0
            print "ERROR: Scheduler::get_tick() called, but not in an event"
        int((time + time_offset) * 1000)


    # switch the current scheduler to this one, so named to discourage
    #   any calls except from within Scheduler or Vscheduler methods.
    def use_internal()
        if sched_nesting == 0 // scheduler virtual time is realtime - starttime
            sched_ideal_time = time_get()
        time = sched_ideal_time - time_offset
        // otherwise scheduler virtual time was exactly set by current event
        the_sched = this


    def start_use()
        use_internal()
        sched_nesting = sched_nesting + 1


    def finish_use()
        sched_nesting = sched_nesting - 1


    # nested time mapping stops here
    def r2v(r)
        r - time_offset

    def v2r(v)
        v + time_offset


    # make time greater by delta (for time synchronization)
    #     Note: if delta is large, this could unleash many scheduled events
    #           at once. Normally, this would only be used to correct clock
    #           skews of a few milliseconds
    def bump_time(delta)
        time_offset = time_offset - delta
        time = time + delta


class Vscheduler (Time_map)
    var name  // optional name for debugging
    var time
    var parent // the scheduler that provides our time reference
    var queue // queue of pending events, sorted by virtual time
    var next_vtime // either INFINITY or queue.last()[0], and the time
            // when we expect an activate message, which causes this
            // scheduler to dispatch an event. If an activate message
            // arrives earlier than next_vtime, we ignore it because there
            // is always a message scheduled for the correct event time.
            // We have to reschedule (and possibly create extra activate
            // messages when the time map changes.
    var adjust_num // sequence number to cancel scheduled calls to adjust_map

    def init(rts, optional s = "")
        parent = rts
        super.init(0, 0, 1.0) // initial tempo is 60 bpm = 1 bps
        time = 0.0
        queue = []
        next_vtime = INFINITY
        adjust_num = 0
        name = s

    # schedule an event: just like cause in Schedule, except
    # event is scheduled relative to this virtual time
    def cause(when, target, message, rest parms)
        // display "vcause 1", time_get(), when, time, time + when, target, message, parms
        when = time + when
        queue.append([when, target, message, parms])
        queue.resort()
        // display "vcause 2", queue.last()[0], len(queue)
        if next_vtime > when
            reschedule()


    # unschedule all pending events; do not execute/dispatch them
    def flush()
        queue.clear()
        next_vtime = INFINITY


    def start_use()
        parent.start_use()
        the_sched = this
        time = map_from_parent(parent.time) // update the local time


    def finish_use()
        parent.finish_use() // unfreeze global time updating


    # (recursive) mapping from real time to local virtual time
    def r2v(now)
        map_from_parent(parent.r2v(now))

    # (recursive) mapping from local virtual time to real time
    def v2r(vnow)
        parent.v2r(map_to_parent(vnow))

    # note: use map_from_parent() and map_to_parent() to apply
    #   local time_map or its inverse

    # private method to schedule a wake-up call for next event in queue
    def reschedule():
        if len(queue) > 0
            next_vtime = queue.last()[0]
            parent.cause(map_to_parent(next_vtime) - parent.time, 
                         this, 'activate')
        else
            next_vtime = INFINITY


    # internal method called by parent scheduler to run the next event
    # in the queue. Since activate is always scheduled for the next
    # event in the queue, we can ignore any activate that arrives early
    # (and in fact we must to eliminate redundant activate messages)
    # If the message is not early, we dispatch one or more events and
    # schedule another activate message unless the queue is empty.
    def activate()
        time = map_from_parent(parent.time)
        // display "activate", time, parent.time, next_vtime

        if time < next_vtime - EPSILON
            return // ignore this activate, another will come later
        while time >= next_vtime - EPSILON
            var event = queue.unappend()
            if len(queue) > 0
                next_vtime = queue.last()[0]
            else
                next_vtime = INFINITY
            time = event[0] // should not be necessary
            var target = event[1]
            var message = event[2]
            var parms = event[3]
            the_sched = this
            // display "vdispatch", time_get(), time, target, message, parms
            general_apply(target, message, parms)
        reschedule() // in case no wake-up for next_vtime


    # set the scheduler time to v. The time map
    # currently maps parent.time to this.time. The map is changed to map
    # parent.time to v
    def set_vtime(v)
        rt_base = parent.time
        vt_base = v
        time = v
        reschedule()


    # set the "tempo" The time map currently maps parent.time to this.time.
    # At that point, the tempo changes.
    def set_bpm(bpm)
        set_bps(bpm / 60)

    def set_bps(b)
        adjust_num = adjust_num + 1 // cancel any callback
        if b <= 0
            print "ERROR: set_bps("; bps; ") ignored!"
        else
            rt_base = parent.time
            vt_base = time
            bps = b
            reschedule()

    def set_period(p):
        if p <= 0:
            print "ERROR: set_period("; p; ") ignored!"
        else:
            set_bps(1 / p)


    def set_time_map(rt, vt, bps_)
        adjust_num = adjust_num + 1 // cancel any callback
        rt_base = rt
        vt_base = vt
        bps = bps_
        reschedule()


    # adjust_map takes in a estimated time_map (e.g. from foot tapping) and
    # smoothly interpolates from this time map to the new one. It is assumed
    # that the parent is rtsched.
    #  est_map - the estimated time_map, mapping real time to OUTPUT time.
    #            est_map must NOT be modified until at least the next call
    #            to this adjust_map method.
    #  conv_dist - the convergence distance in beats, larger is smoother
    #  lag - latency. Assume this scheduler schedules everything early by
    #        lag because event OUTPUT happens lag seconds after events are
    #        scheduled. To make OUTPUT converge to est_map, we need to
    #        (eventually) schedule at (the time specified by est_map) - lag.
    #
    def adjust_map(est_map, conv_dist, lag):
        // THIS BLOCK OF STUFF IS FOR DEBUGGING
        //print name, "adjust_map: local map",
        //show()
        //print "est_map",
        //est_map.show()
        //var diff = time - est_map.map_from_parent(rtsched.time + lag)
        //display "adjust_map", time, diff
        
        // cancel any pending adjust_num_n calls:
        adjust_num = adjust_num + 1
        // first time to set the time_map (STOPPED_BPS) or converged time
        // maps indicated by the beat according to est_map after lag
        // seconds equal to the current beat. If either is true, just
        // copy the estimated map to the current map
        if bps <= STOPPED_BPS or 
           within(time, est_map.map_from_parent(rtsched.time + lag), 0.002)
            // similar to set_time_map, but we have to shift rt_base by lag:
            vt_base = est_map.vt_base
            rt_base = est_map.rt_base - lag
            bps = est_map.bps
            reschedule()
        else:
            //display "adjust_map calling use()", sched_nesting
            start_use()
            lagged_time = rtsched.time + lag
            // change rt_base, vt_base to now + latency when tempo change 
            //  will take effect
            vt_base = map_from_parent(lagged_time)
            rt_base = lagged_time
            // Compute tempo in bps, s.t. starting at rt_base, we will
            // intersect current time map after conv_dist beats. 
            // The equation is bps = (conv_dist * est_map.bps) / den,
            // where den is given below. We need den > 0 to get a
            // finite positive bps. Moreover, let's limit bps to
            // 2 * est_map.bps, i.e. go at most twice the estimated
            // tempo in order to catch up, so bps / est_map.bps < 2.
            // Therefore bps / est_map.bps = conv_dist / den < 2,
            // or conv_dist < 2 * den.
            // den is the "denominator" in Eq. 8 of the 2011 NIME paper
            var den = est_map.rt_base * est_map.bps -
                      rt_base * est_map.bps - est_map.vt_base +
                      vt_base + conv_dist
            if conv_dist < 2 * den:
                bps = (conv_dist * est_map.bps) / den
            else:
                bps = 2 * est_map.bps // it will take more than conv_dist
                // to catch up, but this is as fast as we can go
            // new time map is correct except that it expresses the desired
            // output timing. We need to shift by latency to determine how
            // to schedule events. They will then match the desired output
            // timing because the output is delayed by latency
            rt_base = rt_base - lag
            next_vtime = INFINITY // force reschedule in cause()
            cause(conv_dist / 2, this, 'adjust_map_n', est_map, conv_dist,
                  lag, adjust_num)
            finish_use()
            

    # private method used by adjust_map()
    def adjust_map_n(est_map, conv_dist, lag, n)
        if adjust_num == n
            adjust_map(est_map, conv_dist, lag)

    # debugging support: print functions to be called in future
    #    the format is method@time with [p1, p2, p3, ...]
    #    (the object, if any, is not printed)
    def show_queue():
        start_use()
        for i = len(queue) - 1 to -1 by -1:
            var ev = queue[i]
            print "    "; ev[2]; "@"; ev[0]; " with ", ev[3]
        print "   Parent time "; parent.time; " Virt time "; time
        print "   activate at parent times:"
        for i = len(parent.queue) - 1 to -1 by -1:
            ev = parent.queue[i]
            if ev[1] == this:
                print "    "; ev[2]; "@"; ev[0]; "->"; map_from_parent(ev[0]);
                print " with ", ev[3]
        finish_use()
        
# This function is used to apply a function to an array of parameters.
# If target is nil, a function is called. If target is an object, the
# "function" is interpreted as a method and the method is invoked with
# the set of parameters. A run-time error occurs if target is not an
# object (or nil), or if message is not a valid function or method name.
#
def general_apply(target, message, parms):
    if target:
        sendapply(target, message, parms)
    else
        apply(message, parms)


# application should call this to create schedulers and prepare
# to enter real-time processing
#
sched_initialized = nil // detects if we've started before
def sched_init()
    if sched_initialized // do not restart timer, reuse scheduler objects
        // do a reset on existing objects
        rtsched.init()
        vtsched.init(rtsched)
    else // start from nothing
        time_start(2)
        rtsched = Scheduler()
        vtsched = Vscheduler(rtsched)
    sched_initialized = t

midi_in = nil
osc_enabled = nil
poll_function = nil

def sched_run()
    // application should call this after initilization
    sched_running = t
    rtsched.time_offset = time_get()
    while sched_running
        var time = time_get()
        rtsched.poll(time) // side effect: sets rtsched.time
        if osc_enabled:
            osc_server_poll()
        if midi_in:
            midi_in.poll()
        if poll_function
            funcall(poll_function)
        time_sleep(0.002) // delay 2ms to allow other processes to run

def sched_stop()
    sched_running = false

def wxs_sched_poll()
    var time = time_get()
    rtsched.poll(time)
    if osc_enabled:
        osc_server_poll()
    if midi_in:
        midi_in.poll()
    if poll_function
        funcall(poll_function)

// Call this after setting up user interface. This should
// be the last thing called by the initial file loaded by
// wxserpent.
def sched_launch(optional period = 2)
    rtsched.time_offset = time_get()
    wxs_timer_start(period, 'wxs_sched_poll')
